{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamiltonian Monte Carlo\n",
    "### (Or: watch your \"p's\"s and \"q's\")\n",
    "\n",
    "Hamiltonian physics is a re-imagining (of sorts) of the fundamental idea of the conservation of energy. \n",
    "\n",
    "The classical formulation goes something like the following. Assume we have a particle, whose position is denoted by the variable $\\bf{q}$. The momentum of such a particle is defined by the fomula $\\bf{p=mv}$, where $\\bf{v}$ is the first derivative of the position variable, $\\bf{\\dot{q}}$.\n",
    "\n",
    "The kinetic and potential energy of this particle may be represented as:\n",
    "\n",
    "$$\\bf{K(p,q) = \\frac{1}{2}m\\dot{q}^2 \\hspace{1in} U(q)} $$\n",
    "\n",
    "With the $Hamiltonian$ written as the sum of the kinetic and potential energies (scalable to many particles, if needed):\n",
    "\n",
    "$$\\bf{H = K(p,q) + U(q) = \\frac{1}{2}m\\dot{q}^2 + U(q) }$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\bf{H = \\frac{p}{2m} + U(q)}$$\n",
    "\n",
    "The equation of motion for the particle (or system, for many particles) are given by $Hamilton's~ Equations$:\n",
    "\n",
    "$$\\boxed{\\bf{q=\\frac{\\partial H}{\\partial p}}} \\hspace{1in} \\boxed{\\bf{p=-\\frac{\\partial H}{\\partial q}}}$$\n",
    "\n",
    "This is all fine and dandy, but really? $Why~do~we~care$?\n",
    "\n",
    "Keep this in mind as we move forward: the solution of Hamilton's equations yields a trajectory $-$ positions and momenta as functions of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some (re-)definitions\n",
    "\n",
    "For purposes here, Markov chain Monte Carlo (MCMC) is a method to determine expectations (some value of interest) from the posterior distribution of our model. To avoid a [traxoline](https://people.physics.tamu.edu/krisciunas/Traxoline.pdf) moment, the best explanation for this that I've found is: the posterior distribution is a probability distribution that represents your updated beliefs about the parameter after having seen the data. From this probability distribution, we can estimate the value of interest, as well as uncertainties in said value. \n",
    "\n",
    "We need the MCMC to converge to the true expectation value (true estimate) quickly. Fast convergence requires strong conditions of $\\bf{ergodicity}$ - that is, a parameter space may be sufficiently explored statistically by MCMC in a finite amount of time. Specifically, the condition of geometric ergodicity is desirable. In this condition, MCMC estimators follow the central limit theorum, and the properly normalized sum of the probability distribution or posterior, tends towards a normal, or Gaussian distribution. $\\bf{Geometric~ergodicity}$ applies to manifolds (high-dimentional surfaces) and has been historically important in the development of differential geometric analyses, such as General Relativity. \n",
    "\n",
    "$Hamiltonian~Monte~Carlo~(\\bf{HMC})$ is unique in that when it fails to converge, it is recognisable. For example, with the split $\\hat{\\bf{R}}$ statistic, which for well-behaved parameter spaces, should be very near 1.0, and values above 1.1 indicate problems with the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamiltonian Monte Carlo application\n",
    "\n",
    "Using Hamiltonian dynamics to sample from a distribution requires translating the density function for this distribution to a potential energy function and introducing \"momentum\" variables to go with the original variables of interest (now seen as \"position\" variables). We can then simulate a Markov chain in which each iteration resamples the momentum and then does a Metropolis update with a proposal found using Hamiltonian dynamics.\n",
    "\n",
    "The first step of the HMC process changes only the momentum, with new values randomly extracted from a Gaussian distribution. In the second step, a Metropolis update is performed, using Hamiltonian dynamics to propose a new state. Care must be taken in choosing the number of steps and step size to avoid problems, such as periodicity in parameter space exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why HMC?\n",
    "\n",
    "Let's explore an example, at least graphically, why one might wish to use HMC over other types of MCMC estimation. This example will contrast HMC and random-walk Metropolis MCMC via a 100-dimensional multivariate Gaussian distribution in which the varialbes are independant, with means of zero, and standard deviations of 0.01, 0.02, ..., 0.99, 1.00. The results of the simulations are best seen in a series of plots.\n",
    "\n",
    "<img src=\"Location_plot.jpg\">\n",
    "<img src=\"Accuracy.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "1. http://www.mcmchandbook.net/HandbookChapter5.pdf\n",
    "2. http://stats.stackexchange.com/questions/58564/help-me-understand-bayesian-prior-and-posterior-distributions\n",
    "3. http://www.nyu.edu/classes/tuckerman/stat.mech/lectures/lecture_1/node4.html\n",
    "4. http://mc-stan.org/users/documentation/case-studies/pystan_workflow.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example: The stellar IMF with Metropolis-Hastings and with HMC\n",
    "\n",
    "Salpeter (1955) found that the stellar initial mass function (IMF) for stars above 1$M_\\odot$ has a power law form:\n",
    "\n",
    "$\\frac{dN}{dM} \\propto \\frac{M}{M_\\odot}^{-\\alpha} ~~ or ~~ \\frac{dN}{dlogM} \\propto \\frac{M}{M_\\odot}^{1-\\alpha}$\n",
    "\n",
    "and he estimated $\\alpha=2.35$.\n",
    "\n",
    "Here we will create a set of test stellar mass data, distributed according to the Salpeter mass function, and then we will perform a Markov Chain to guess this (known) slope.  \n",
    "We will give an example using the Metropolis MCMC, and then perform the same procedure with Hamiltonian dynamics.\n",
    "\n",
    "We are given then a set of N stellar masses, with negligible errors in the measurements.\n",
    "Assuming that the minimum and maximum masses are known, the likelihood of the problem is: \n",
    "\n",
    "$\\mathcal L(\\{M_1,M_2,\\ldots,M_N\\};\\alpha) = \\prod_{n=1}^N p(M_n|\\alpha) = \\prod_{n=1}^N c\\left(\\frac{M_n}{M_\\odot}\\right)^{-\\alpha}$\n",
    "\n",
    "where the normalization constant c can be found by:\n",
    "\n",
    "$\\int_{M_{min}}^{M_{max}}c M^{-\\alpha} dM = 1 \\Rightarrow c\\frac{M_{max}^{1-\\alpha}-M_{min}^{1-\\alpha}}{1-\\alpha}=1$\n",
    "\n",
    "First, let's create a function that will construct a Salpeter IMF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "def sampleFromSalpeter(N, alpha, M_min, M_max):\n",
    "    # Draw random samples from a Salpeter IMF.\n",
    "    # N     ... number of samples.\n",
    "    # alpha ... power-law index.\n",
    "    # M_min ... lower bound of mass interval.\n",
    "    # M_max ... upper bound of mass interval.\n",
    "    # Convert limits from M to logM.\n",
    "    log_M_Min = math.log(M_min)\n",
    "    log_M_Max = math.log(M_max)\n",
    "    # Since the Salpeter SMF has a negative slope, maximum likelihood occurs at M_min\n",
    "    maxlik = math.pow(M_min, 1.0 - alpha)\n",
    "    \n",
    "    # Prepare array for output masses.\n",
    "    Masses = []\n",
    "    # Fill in array.\n",
    "    while (len(Masses) < N):\n",
    "        # Draw a candidate from logM interval.\n",
    "        logM = random.uniform(log_M_Min,log_M_Max)\n",
    "        M    = math.exp(logM)\n",
    "        # Compute likelihood of candidate from Salpeter SMF.\n",
    "        likelihood = math.pow(M, 1.0 - alpha)\n",
    "        # Accept randomly.\n",
    "        u = random.uniform(0.0,maxlik)\n",
    "        if (u < likelihood):\n",
    "            Masses.append(M)\n",
    "    return Masses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the logarithmic likelihood function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateLogLikelihood(params, D, N, M_min, M_max):\n",
    "    # Define logarithmic likelihood function.\n",
    "    # params ... array of fit params, here just alpha\n",
    "    # D      ... sum over log(M_n)\n",
    "    # N      ... number of data points.\n",
    "    # M_min  ... lower limit of mass interval\n",
    "    # M_max  ... upper limit of mass interval\n",
    "    alpha = params[0]  # extract alpha\n",
    "    # Compute normalisation constant.\n",
    "    c = (1.0 - alpha)/(math.pow(M_max, 1.0-alpha)\n",
    "                        - math.pow(M_min, 1.0-alpha))\n",
    "    # return log likelihood.\n",
    "    return N*math.log(c) - alpha*D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate our toy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N      = 1000000  # Draw 1 Million stellar masses.\n",
    "alpha  = 2.35\n",
    "M_min  = 1.0\n",
    "M_max  = 100.0\n",
    "log_M_min  = np.log10(M_min)\n",
    "log_M_max  = np.log10(M_max)\n",
    "Masses = sampleFromSalpeter(N, alpha, M_min, M_max)\n",
    "LogM   = np.log(np.array(Masses))\n",
    "D      = np.mean(LogM)*N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are ready to initialize our MCMC as we saw the previous time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial guess for alpha as a list.\n",
    "guess = [3.0]\n",
    "# Prepare storing MCMC chain as list of lists.\n",
    "A = [guess]\n",
    "# define stepsize of MCMC.\n",
    "stepsizes = [0.0005]  # list of stepsizes\n",
    "accepted  = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate = 0.7706\n"
     ]
    }
   ],
   "source": [
    "# Metropolis-Hastings with 10,000 iterations.\n",
    "for n in range(10000):\n",
    "    old_alpha  = A[len(A)-1]  # old parameter value as array\n",
    "    old_loglik = evaluateLogLikelihood(old_alpha, D, N, M_min,\n",
    "                    M_max)\n",
    "    # Suggest new candidate from Gaussian proposal distribution.\n",
    "    new_alpha = np.zeros([len(old_alpha)])\n",
    "    for i in range(len(old_alpha)):\n",
    "        # Use stepsize provided for every dimension.\n",
    "        new_alpha[i] = random.gauss(old_alpha[i], stepsizes[i])\n",
    "    new_loglik = evaluateLogLikelihood(new_alpha, D, N, M_min,\n",
    "                    M_max)\n",
    "    # Accept new candidate in Monte-Carlo fashing.\n",
    "    if (new_loglik > old_loglik):\n",
    "        A.append(new_alpha)\n",
    "        accepted = accepted + 1.0  # monitor acceptance\n",
    "    else:\n",
    "        u = random.uniform(0.0,1.0)\n",
    "        if (u < math.exp(new_loglik - old_loglik)):\n",
    "            A.append(new_alpha)\n",
    "            accepted = accepted + 1.0  # monitor acceptance\n",
    "        else:\n",
    "            A.append(old_alpha)\n",
    "\n",
    "print(\"Acceptance rate = \"+str(accepted/10000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discard first half of MCMC chain and thin out the rest.\n",
    "Clean = []\n",
    "for n in range(5000,10000):\n",
    "    if (n % 10 == 0):\n",
    "        Clean.append(A[n][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  2.35290377401\n",
      "Sigma: 0.00124581193872\n"
     ]
    }
   ],
   "source": [
    "# Print Monte-Carlo estimate of alpha.\n",
    "print(\"Mean:  \"+str(np.mean(Clean)))\n",
    "print(\"Sigma: \"+str(np.std(Clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEPCAYAAABcA4N7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d8418d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "plt.hist(Clean, 20, histtype='step', lw=2)\n",
    "plt.xticks([2.346,2.348,2.35,2.352,2.354],\n",
    "           [2.346,2.348,2.35,2.352,2.354])\n",
    "plt.xlim(2.345,2.355)\n",
    "plt.xlabel(r'$\\alpha$', fontsize=16)\n",
    "plt.ylabel(r'$\\cal L($Data$;\\alpha)$', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the same example using a Hamiltonian MC.  This means that, instead of our next guess being completely random, it will be instructed by the gradient of the log-likelihood:\n",
    "\n",
    "$\\frac{\\partial log\\cal{L}}{\\partial\\alpha} = -D - \\frac{N}{1-\\alpha}\\left[1+\\frac{1-\\alpha}{M_{max}^{1-\\alpha}-M_{min}^{1-\\alpha}}\\left(M_{max}^{1-\\alpha}logM_{min}-M_{min}^{1-\\alpha}logM_{max}\\right)\\right]$\n",
    "\n",
    "First, we will need a function that evaluates this gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateGradient(params, D, N, M_min, M_max, logMmin, logMmax):\n",
    "\n",
    "    alpha = params[0]  # extract alpha\n",
    "    grad = logMmin*math.pow(M_min, 1.0-alpha) - logMmax*math.pow(M_max, 1.0-alpha)\n",
    "    grad = 1.0 + grad*(1.0 - alpha)/(math.pow(M_max, 1.0-alpha)\n",
    "            - math.pow(M_min, 1.0-alpha))\n",
    "    grad = -D - N*grad/(1.0 - alpha)\n",
    "    return np.array(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, like before, we need to initialize our chain and set a stepsize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guess = [3.0]\n",
    "A = [guess]\n",
    "# define stepsize of HMC.\n",
    "stepsize = 0.00004\n",
    "accepted  = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we are going to need is an algorithm that evolves the dynamics of the system according to its \"Hamiltonian\", in this case the gradient of the log likelihood function.  Here we are going to use the Leapfrog algorithm, commonly used to integrate Hamiltonian systems since it exactly preserves energy at the end of each step.\n",
    "\n",
    "Leapfrog integrates the equations of motion of a system by splitting the time step, dt, into two halves.  In short, the algorithm can be summarized as follows:\n",
    "\n",
    "Starting from an initial condition (${\\bf{x_0,p_0}}$),\n",
    "\n",
    "1. Take half a step to update the momentum: \n",
    "\n",
    "$p_i(t+dt/2) = p_i(t) - dt/2\\frac{\\partial U}{\\partial x_i(t)}$\n",
    "\n",
    "2. Take an entire step to update the position:\n",
    "\n",
    "$x_i(t+dt) = x_i(t) + dt\\frac{\\partial K}{\\partial p_i(t+dt/2)}$\n",
    "\n",
    "3. Take the other half step to update the momentum:\n",
    "\n",
    "$p_i(t+dt) = p_i(t+dt/2) - dt/2\\frac{\\partial U}{\\partial x_i(t+dt)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate = 0.6017679646407071\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Hamiltonian Monte-Carlo.\n",
    "for n in range(50000):\n",
    "    old_alpha  = A[len(A)-1]\n",
    "    # Remember, energy = -loglik\n",
    "    old_energy = -evaluateLogLikelihood(old_alpha, D, N, M_min, M_max)\n",
    "    old_grad   = -evaluateGradient(old_alpha, D, N, M_min, M_max, log_M_min, log_M_max)\n",
    "\n",
    "    new_alpha = copy.copy(old_alpha)  # deep copy of array\n",
    "    new_grad  = copy.copy(old_grad)   # deep copy of array\n",
    "    # Suggest new candidate using gradient + Hamiltonian dynamics.\n",
    "    # draw random momentum vector from unit Gaussian.\n",
    "    p = random.gauss(0.0, 1.0)\n",
    "    H = np.dot(p,p)/2.0 + old_energy    # compute Hamiltonian\n",
    "\n",
    "    # Do 5 Leapfrog steps.\n",
    "    for tau in range(5):\n",
    "        # make half step in p\n",
    "        p         = p - stepsize*new_grad/2.0\n",
    "        # make full step in alpha\n",
    "        new_alpha = new_alpha + stepsize*p\n",
    "        # compute new gradient\n",
    "        new_grad  = -evaluateGradient(old_alpha, D, N, M_min,\n",
    "                         M_max, log_M_min, log_M_max)\n",
    "        # make half step in p\n",
    "        p         = p - stepsize*new_grad/2.0\n",
    "\n",
    "    # Compute new Hamiltonian. Remember, energy = -loglik.\n",
    "    new_energy = -evaluateLogLikelihood(new_alpha, D, N, M_min,\n",
    "                     M_max)\n",
    "    new_grad  = -evaluateGradient(old_alpha,D, N, M_min,\n",
    "                         M_max, log_M_min, log_M_max)\n",
    "    newH       = np.dot(p,p)/2.0 + new_energy\n",
    "    dH         = newH - H\n",
    "\n",
    "    # Accept new candidate in Monte-Carlo fashion.\n",
    "    if (dH < 0.0):\n",
    "        A.append(new_alpha)\n",
    "        accepted = accepted + 1.0\n",
    "    else:\n",
    "        u = random.uniform(0.0,1.0)\n",
    "        if (u < math.exp(-dH)):\n",
    "            A.append(new_alpha)\n",
    "            accepted = accepted + 1.0\n",
    "        else:\n",
    "            A.append(old_alpha)\n",
    "\n",
    "print(\"Acceptance rate = \"+str(accepted/float(len(A))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  2.35058263556\n",
      "Sigma: 0.00143177309357\n"
     ]
    }
   ],
   "source": [
    "# Discard first half of MCMC chain and thin out the rest.\n",
    "Clean = []\n",
    "for n in range(len(A)//2,len(A)):\n",
    "    if (n % 10 == 0):\n",
    "        Clean.append(A[n][0])\n",
    "        \n",
    "# Print Monte-Carlo estimate of alpha.\n",
    "print(\"Mean:  \"+str(np.mean(Clean)))\n",
    "print(\"Sigma: \"+str(np.std(Clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEPCAYAAACDTflkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF1VJREFUeJzt3X+0XWV95/H3p4ig+AtKjBGCwTF2GpwR9ZbapcuijErV\nWfirFFercYZl1DLWKjM2WJe/ZpgJqFhbB2uqjHGqxYzKgEhRYGlbRxCDRYUgEkmQZAJBBX+Mgga+\n88fZgcPlJjln33PvPif3/VrrrLPPs5+9z3c/ubnf++wfz5OqQpKkNn6t6wAkSZPLJCJJas0kIklq\nzSQiSWrNJCJJas0kIklqzSQiSWrNJCJJas0kIklq7UFdBzDXDj300Fq2bFnXYUjSRLnqqqt+UFWL\n9lZvn08iy5YtY8OGDV2HIUkTJclNg9TzdJYkqTWTiCSpNZOIJKk1k4gkqTWTiCSpNZOIJKm1zpJI\nkgOTXJnkm0muTfKupvyQJJckuaF5P7hvm9OSbEpyfZLndxW7JKmny57IXcBzqurJwNHA8UmeDqwG\nLquq5cBlzWeSrABOAo4CjgfOTrJfJ5FLkoAOHzas3uTuP2s+7t+8CjgBOLYpXwd8GfizpvzcqroL\n2JxkE3AMcPn8RS11b9nqz49kP1vWvHAk+9HC1uk1kST7Jbka2AFcUlVfAxZX1famyi3A4mb5MODm\nvs23NmUz7XdVkg1JNtx2221zFL0kqdNhT6rqbuDoJI8CzkvypGnrK0m12O9aYC3A1NTU0NtLk6Bt\nT2JUPRkJxuTurKq6A/gSvWsdtyZZAtC872iqbQOW9m12eFMmSepIl3dnLWp6ICR5CPBc4DvABcDK\nptpK4Pxm+QLgpCQHJDkSWA5cOb9RS5L6dXk6awmwrrnD6teA9VV1YZLLgfVJTgZuAk4EqKprk6wH\nNgI7gVOa02HSxPGUkvYVXd6d9S3gKTOU/xA4bjfbnA6cPsehSZIGtM/PJyKNM2+z1aQbiwvrkqTJ\nZBKRJLVmEpEktWYSkSS1ZhKRJLVmEpEktWYSkSS1ZhKRJLVmEpEktWYSkSS15rAnUksOoijZE5Ek\nzYI9EWmWHERRC5lJRFqgZnM6zsSpXTydJUlqzZ6ItMDMphfhzQSazp6IJKk1k4gkqTWTiCSpNZOI\nJKk1k4gkqTWTiCSpNZOIJKk1k4gkqbXOkkiSpUm+lGRjkmuTvLEpf2eSbUmubl4v6NvmtCSbklyf\n5PldxS5J6unyifWdwKlV9Y0kDweuSnJJs+79VfXe/spJVgAnAUcBjwUuTfLEqrp7XqOWJN2rs55I\nVW2vqm80yz8FrgMO28MmJwDnVtVdVbUZ2AQcM/eRSpJ2ZyyuiSRZBjwF+FpT9IYk30pyTpKDm7LD\ngJv7NtvKnpOOJGmOdZ5EkjwM+Azwp1X1E+BDwOOBo4HtwPta7HNVkg1JNtx2220jjVeSdJ9Ok0iS\n/eklkE9U1WcBqurWqrq7qu4B/ob7TlltA5b2bX54U/YAVbW2qqaqamrRokVzdwCStMB1eXdWgI8C\n11XVWX3lS/qqvQS4plm+ADgpyQFJjgSWA1fOV7ySpAfq8u6sZwCvBL6d5Oqm7K3AK5IcDRSwBXgt\nQFVdm2Q9sJHenV2neGeWJHWrsyRSVV8BMsOqi/awzenA6XMWlCRpKJ1fWJckTS6TiCSpNZOIJKk1\nk4gkqTWTiCSpNZOIJKk1k4gkqTWTiCSpNZOIJKk1k4gkqTWTiCSpNZOIJKk1k4gkqTWTiCSpNZOI\nJKk1k4gkqTWTiCSpNZOIJKm1LudYlzShlq3+fOttt6x54QgjUdfsiUiSWrMnImlgs+lFzKb3ovE1\nVBJJ8nTgeODpwGOBhwA/AK4H/gH431V1+6iDlCSNp4FOZyVZmeTbwFeBNwEPBW4AvgbcDvw28BFg\nW5KPJTlyjuKVJI2RvfZEknwLWAR8HHgVcHVV1Qz1Hgm8CPhDYGOSV1fVp0YcrzRSnmKRZmeQ01kf\nBT5cVXfuqVJV/Rj4BPCJJE8GHjOC+CRJY2yvSaSqPrBrOcljquqWAbb5JvDNWcYmzRtvO5XaGfYW\n3+8lWZPk4Okrkjw4yUMG3VGSpUm+lGRjkmuTvLEpPyTJJUluaN4P7tvmtCSbklyf5PlDxi5JGrFh\nk8jvAiuAG5O8LclBfeueA/xkiH3tBE6tqhX07vY6JckKYDVwWVUtBy5rPtOsOwk4it4dYmcn2W/I\n+CVJIzRsEvkxsOvayLuBLUmuSPJ14DzgG4PuqKq2V9U3muWfAtcBhwEnAOuaauuAFzfLJwDnVtVd\nVbUZ2AQcM2T8kqQRGvZhw3X0ng/5AHAH8GB6d2ytAD4NvK5NEEmWAU+hd8vw4qra3qy6BVjcLB8G\nXNG32dambKb9rQJWARxxxBFtQpIkDWDYJHI08PKqumhXQZL3An8MnAE8Dzh3mB0meRjwGeBPq+on\nSe5dV1WV5AG3E+9NVa0F1gJMTU0Nvb0kaTDDJpHtwKP7C6rqHuCDzS//9zBEEkmyP70E8omq+mxT\nfGuSJVW1PckSYEdTvg1Y2rf54U2ZJKkjwyaR/wGsSXJdVX1t2rqb6T2UOJD0ss5Hgeuq6qy+VRcA\nK4E1zfv5feWfTHIWvVNqy4Erh4xf+xgfFpS6NWwSWQMcC/yfJF8ELgI2A4cAbwe+O8S+ngG8Evh2\nkqubsrc237E+ycnATcCJAFV1bZL1wEZ6d3adUlV3Dxm/JGmEhkoiVbUzyfHAKcBrgb/sW/1j4OVD\n7OsrQHaz+rjdbHM6cPqg36GFw4cFpW4MPRR8Ve2kd3fWB5IsBp4A3AN8s6p+PuL4JEljbFbziVTV\nrcCtI4pFkjRhnNlQktSaSUSS1JpJRJLUmklEktTa0EkkyduT/Pluyl+T5MDRhCZJGndteiLvBN6x\nm/IPAzcl+bNZxCRJmhBtbvE9EphpUMMjgYOAZwLPmk1QkqTJ0OZhw5v2Ur6RZgRdSdK+zQvrkqTW\nWj2xnuTJwG8AD7iIXlUfn21QkqTJMFQSSfIo4PP05kSH+wZQ7L9GYhKRpAVi2NNZ/xX4dXoXzgO8\nBHgO8AngRpzzXJIWlGGTyPPpJZJdc51vraovV9WrgEuBN44yOEnSeBs2iSwBNjeTQd0JPLxv3WcB\nJ3WQpAVk2CRyC71ZDKE36+Dv9K17wkgikiRNjGHvzvoKvYvq5wP/E3hHkmX0pqtdSW8edEnSAjFs\nEnkX8Nhm+T30LrL/AfBQegnkDaMLTZI07oadY/17wPea5V8BpzYvSdICNNQ1kSQ3Ng8azrTuSUlu\nHE1YkqRJMOyF9WXAAbtZdyDwuFlFI0maKG3GzpppBF+AKeCOWcQiSZowe70mkuRNwJuajwV8Lskv\np1V7CL1bf88dbXiSpHE2yIX1G4HLmuWVwAbgtml17qI3BPxHRheaJGnc7TWJVNX59J4LIQnAu6tq\n8yi+PMk5wIuAHVX1pKbsncBruC9RvbWqLmrWnQacDNwN/ElVfWEUcUiS2hn2Ft9/N+Lv/xjwQR44\n8u/7q+q9/QVJVgAnAUfRe1bl0iRPbIZg0QRbtvrzXYcgqaVO5xOpqn9snngfxAnAuVV1F7A5ySZ6\nowZfPuj3SZJGa1znE3lDklfRu/5yalXdDhzGfaMHA2xtyrSP2LLG8TulSTOO84l8CHg8cDSwHXjf\nsDtIsirJhiQbbrtt+j0AkqRRGbv5RKrq1qq6u6ruAf6G+xLTNmBpX9XDm7KZ9rG2qqaqamrRokWz\nDUmStBvDXhO5dz6RJDPNJzLr50SSLKmq7c3HlwDXNMsXAJ9Mcha9C+vLgStn+32S5tdsbqTwlOf4\nGTaJzDSfyJebz0PPJ5Lk74BjgUOTbAXeARyb5Gh611m2AK8FqKprk6yn9zzKTuAU78ySpG51Op9I\nVb1ihuKP7qH+6cDpw3yHpPEwm16Et4GPL+cTkSS15nwikqTWhn1O5EB6o/UuoXfNYjtwVVXdOQex\nSZLG3EBJJMkBwJn0xrQ6gPs/ZHhnkg/RG+Nq+ui+kqR92KA9kQvpPVR4PnAR8H16iWQpvQEU3wSs\nAF4wBzFKksbUIPOJ/D7wbODlVXXeDFU+kuRlwKeSvLSqPjvqICVJ42mQJ9ZfAazfTQIBoKo+A/wv\n4A9HFZgkafwNkkSeQm/Qxb25EHjq7MKRJE2SQZLIInrXQPbm+8CjZxeOJGmSDJJEHkpv+tu9+SUz\nzC8iSdp3DXp31mFJHr+XOofPNhhJ0mQZNIl8eoA64f6TU0mS9nGDJJFRz6suSdpH7DWJVNW6+QhE\nkjR5BprZMMkhSZ476E6TPDKJs8dI0j5uoCRSVT8CFif593urm2Q58BfAxbOMTZI05gYexbeq/jbJ\nm5NcDnwOuBr4Eb0JqQ4BHg/8G+Ag4I+cdVCS9n3DzidyVpKvA28B/nPfqgA3AB8EzjaBSNLCMOzM\nhlTVPwH/lOQhwJHAI4Gbq2rrqIOTJI23oZPILlX1C2AjQJJfT3JoVf1gZJFJksbeoJNShd71jl9V\n1ZdnqHI78F+SvK2q7hlhfJJ0r2WrBxkLdmZb1njD6FwY6O4s4H3A3wOXJXnAxFNN4rgAeN0IY5Mk\njblBT2etAP4F8A7gu7up88/Ah4GzRxCXJN1rNr2I2fRetHeDJpGvAA+qqj09JzIFrEiyn3dnSdLC\nMOjprL8CPp7kd/dQ5/XAPc1LkrQADPrE+o+BdwMXJtme5NNJ/iTJb/ZVOxz4flUNPJJvknOS7Ehy\nTV/ZIUkuSXJD835w37rTkmxKcn2S5w/6PZKkuTFoT4Sq+gLwNHqntl5Eb2iTa5JsTvJWYAdw/ZDf\n/zHg+Gllq4HLqmo5cFnzmSQrgJOAo5ptzk6y35DfJ0kaoYGTCEBVfbeqfh84FHgBcAawDXg78FJ6\nQ6AMs79/pDd0Sr8TgF0jB68DXtxXfm5V3VVVm4FNwDHDfJ8kabRaPWxYVT+jN8DixQBJDgSeC7x2\nBDEtrqrtzfItwOJm+TDgir56W5sySVJHWj+x3q+q7gQ+l2TzKPbXt99KMvRsiUlWAasAjjjiiFGG\nJEnqM9TprL2pqmv2Xmuvbk2yBKB539GUbwOW9tU7vCmbKY61VTVVVVOLFi0aQUiSpJmMNImMyAXA\nymZ5JXB+X/lJSQ5IciSwHLiyg/gkSY2RnM5qK8nfAccChybZSu+J+DXA+iQnAzcBJwJU1bVJ1tMb\n9HEncIoPNUpStzpNIlX1it2sOm439U8HTp+7iCRJw+g0iUjSfJntGFqOAjyzcbwmIkmaEPZEJO3T\nZtuDcBTgPbMnIklqzSQiSWrNJCJJas1rIhoJzxtLC5M9EUlSa/ZENFLeSy8tLPZEJEmtmUQkSa2Z\nRCRJrZlEJEmtmUQkSa2ZRCRJrZlEJEmtmUQkSa2ZRCRJrZlEJEmtmUQkSa2ZRCRJrZlEJEmtmUQk\nSa2ZRCRJrZlEJEmtmUQkSa2N7cyGSbYAPwXuBnZW1VSSQ4BPAcuALcCJVXV7VzFK0kI37j2RZ1fV\n0VU11XxeDVxWVcuBy5rPkqSOjHsSme4EYF2zvA54cYexSNKCN7ans4ACLk1yN/DhqloLLK6q7c36\nW4DFM22YZBWwCuCII46Yj1j3CctWf77rECRNmHFOIs+sqm1JHg1ckuQ7/SurqpLUTBs2CWctwNTU\n1Ix1JEmzN7ZJpKq2Ne87kpwHHAPcmmRJVW1PsgTY0WmQ+6gta17YdQiSJsRYXhNJclCSh+9aBp4H\nXANcAKxsqq0Ezu8mQkkSjG9PZDFwXhLoxfjJqro4ydeB9UlOBm4CTuwwRkla8MYyiVTVjcCTZyj/\nIXDc/EckSZrJWCYRSRo3s7l7cV++zjiW10QkSZPBnogk7cFsehEL4dkreyKSpNZMIpKk1kwikqTW\nTCKSpNZMIpKk1kwikqTWTCKSpNZMIpKk1kwikqTWTCKSpNZMIpKk1hw7ax+zEMbqkSbNvjwCsD0R\nSVJr9kT2UeP+14u0ECyEEYBNImNmUn5wJAk8nSVJmgV7ImPK01GSJoE9EUlSayYRSVJrJhFJUmsm\nEUlSa15YnwPepitpVMb9afeJ64kkOT7J9Uk2JVnddTyStJBNVE8kyX7AfweeC2wFvp7kgqraOOrv\nGkVvwtt0JbU1KU+7T1pP5BhgU1XdWFW/BM4FTug4JklasCaqJwIcBtzc93kr8Ntz+YX2JiRp9yYt\niQwkySpgVfPxZ0mub72vMx5QdCjwg7b720fZJjOzXR7INpnZnLTLDL+/hvG4QSpNWhLZBizt+3x4\nU3Y/VbUWWDsXASTZUFVTc7HvSWWbzMx2eSDbZGaT3C6Tdk3k68DyJEcmeTBwEnBBxzFJ0oI1UT2R\nqtqZ5D8AXwD2A86pqms7DkuSFqyJSiIAVXURcFGHIczJabIJZ5vMzHZ5INtkZhPbLqmqrmOQJE2o\nSbsmIkkaIws2iSRZmuRLSTYmuTbJG2eoc0KSbyW5OsmGJM+ctn6/JP+c5MJp5W9I8p1mv2fO9bGM\n0ly1S5Kjk1zRt80x83E8ozDbNkmyJcm3d63rKz8kySVJbmjeD56vYxqFOWyX9zT/f76V5Lwkj5qv\nY5qtuWqTvvWnJqkkh871sQysqhbkC1gCPLVZfjjwXWDFtDoP475Tfv8a+M609W8GPglc2Ff2bOBS\n4IDm86O7PtYxaZcvAr/XLL8A+HLXxzpfbQJsAQ6dYb9nAqub5dXAGV0f65i0y/OABzXLZ0xSu8xV\nmzTrltK7qeim3dXp4rVgeyJVtb2qvtEs/xS4jt4T8f11flbNvx5wEHDvBaQkhwMvBD4ybdevB9ZU\n1V3NPnbMzRHMjTlslwIe0Sw/Evi/o49+bsy2TfbgBGBds7wOePFoIp4fc9UuVfXFqtrZfLyC3vNg\nE2EOf1YA3g+8ZYj686PrLDYOL2AZ8H3gETOsewnwHeBHwO/0lX8aeBpwLPf/i/tq4F3A14B/AH6r\n6+Mbk3b5zWZfN9N7QPRxXR/fPLbJ5ubn4ipgVV/5HX3L6f88aa9Rtsu0bT8H/FHXx9d1m9D7g+MD\nzfIWxqgn0nkAXb/odS2vAl66l3rPAi5tll8EnN0sT/9leQ3wV80vhWOaH4p0fZxj0C5/CbysWT5x\n1zaT9GrTJs3nw5r3RwPfBJ7VfL5j2na3d32M49Aufev/HDhvofz/2V2bAA+l90fpI5t1JpFxeQH7\n0zvH+OYB699Ib4yb/0Zv8MctwC3Az4G/bepcDDy7b5vvAYu6PtYxaJcfc9954AA/6fo456NNZih/\nJ/Afm+XrgSXN8hLg+q6Pcxzapfn8auBy4KFdH2PXbQL8K2BH8/9qC7CTXg/nMV0fa9UCTiLNL7KP\nA3+xhzpP6PvF91R6p2Eyrc6x3P8v7tcB726Wn0jv9M3E/CU1h+1yHXBss3wccFXXxzofbULvnPfD\nm/KDgK8Cxzef38P9L6yf2fWxjkm7HA9sZML++JrLNpm2/ZaZkk5Xr4l7Yn2EngG8Evh2kqubsrcC\nRwBU1V8DLwNeleRXwC+AP6jmX3EPzgHOSXIN8Etg5QDbjJO5apfXAB9I8iDgTu4bZXkStG6TJIuB\n85JAb4SIT1bVxc0+1gDrk5xM746bE+frgEZkrtrlg8ABwCXN+iuq6nXzdEyzNVdtMrZ8Yl2S1NqC\nvcVXkjR7JhFJUmsmEUlSayYRSVJrJhFJUmsmEUlSayYRSVJrJhFJUmsmEWkeJdk/yduS3JjkF0ku\nT/IbSaaS/DzJY7uOURqGT6xL8yTJ/sDf05uI6DTgVuBseiO0HkhvcqL/1F2E0vAW8thZ0nz7Y+A5\nwDOr6qsASX4LeCO9Afhe3V1oUjuezpLmz+uAL+5KII076M30eFZV/bCbsKT2TCLSPEjyGOBfAhdN\nW/VgerPbnTXvQUkjYBKR5scTmvfNuwqS7Ae8Cvhe9ebjliaOSUSaH/c074f0lb0eWAHsN//hSKPh\n3VnSPEhyEL0Z7H4InAocDpxJ7/TWvwVeDHypqu7sLEipBZOINE+SPBd4P71pk28D3kJvLu6LgKcB\nj6iq/9ddhNLwTCKSpNa8JiJJas0kIklqzSQiSWrNJCJJas0kIklqzSQiSWrNJCJJas0kIklqzSQi\nSWrt/wMUSDUi7R6wKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ccbea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.hist(Clean, 20, histtype='step', lw=2)\n",
    "#plt.xlim(2.3,2.358)\n",
    "plt.xlabel(r'$\\alpha$', fontsize=16)\n",
    "plt.ylabel(r'$\\cal L($Data$;\\alpha)$', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
