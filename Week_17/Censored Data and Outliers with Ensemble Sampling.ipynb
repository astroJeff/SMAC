{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Censored Data, Outliers, and Ensemble MCMC Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "import emcee\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start our with our problem from last week: fitting a line to data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our linear model from last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our spectrum will be a line with a Gaussian absorption feature\n",
    "def get_val(x, p):\n",
    "    m, b = p\n",
    "    \n",
    "    return m*x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's choose some data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The input values will be called \"truths\"\n",
    "m_truth = 0.5\n",
    "b_truth = 30.5\n",
    "truths = m_truth, b_truth\n",
    "\n",
    "# We will have a wavelength resolution of 1\n",
    "data = np.zeros((100, 3))\n",
    "data[:,0] = np.random.uniform(1, 60, size=100)\n",
    "data[:,2] = np.random.uniform(5, 15, size=100)\n",
    "data[:,1] = get_val(data[:,0], truths) + np.random.normal(loc=0,scale=data[:,2],size=100)\n",
    "\n",
    "\n",
    "# Plot Input values\n",
    "plt.plot(data[:,0], get_val(data[:,0], truths), color='r', label='Input Model')\n",
    "\n",
    "# Plot data points\n",
    "plt.errorbar(data[:,0], data[:,1], yerr=data[:,2], label='Observations', fmt='o')\n",
    "\n",
    "\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last week's priors, likelihood function, and posterior function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ln_prior(p):\n",
    "    \n",
    "    m, b = p\n",
    "    \n",
    "    lp = 0.0\n",
    "    \n",
    "    # No priors are actually necessary here, but we can set something just to be rigorous\n",
    "    # Prior on m\n",
    "    if m<-1.0e99 or m>1.0e99: return -np.inf\n",
    "    \n",
    "    # Prior on b\n",
    "    if b<-1.0e99 or b>1.0e99: return -np.inf\n",
    "    \n",
    "    return lp\n",
    "\n",
    "def ln_likelihood(p, data):\n",
    "        \n",
    "    x_vals = data[:,0]\n",
    "    y_vals = data[:,1]\n",
    "    y_errs = data[:,2]\n",
    "    \n",
    "    y_model = get_val(x_vals, p)\n",
    "    \n",
    "    ll = np.sum(-0.5*np.log(2.0*np.pi*y_errs**2)) + np.sum(-(y_model-y_vals)**2 / (2.0*y_errs**2))\n",
    "    \n",
    "    return ll\n",
    "\n",
    "\n",
    "def ln_posterior(p, data):\n",
    "    \n",
    "    lp = ln_prior(p)\n",
    "    if np.isinf(lp): return -np.inf\n",
    "    \n",
    "    ll = ln_likelihood(p, data)\n",
    "\n",
    "    return lp+ll\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ensemble sampler emcee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than the Metropolis-Hastings algorithm that we coded up last week, we will use the MCMC ensemble sampler, emcee. Make sure you have installed emcee using: \"pip install emcee\". It is a highly used, well-built, code. If you see the acronym MCMC in an astronomy paper, nine times out of ten, the authors are using emcee.\n",
    "\n",
    "emcee works by running multiple Markov Chains (walkers) at the same time. Having multiple chains allows you to determine the step size for the proposal position using knowledge of the distribution of walkers.\n",
    "\n",
    "Rather than initialize one walker in one point in parameter space, we will initialize many walkers (32 in this case), each in a multidimensional \"ball\" around one point. See below for one way to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nwalkers = 32\n",
    "\n",
    "# Choose random positions for our walkers\n",
    "m_set = np.random.normal(loc=20.0, scale=1.0, size=32)\n",
    "b_set = np.random.normal(loc=10.0, scale=1.0, size=32)\n",
    "\n",
    "# The array of initial positions\n",
    "p0 = np.array([m_set, b_set]).T\n",
    "\n",
    "# Print the shape so we can see what it looks like\n",
    "print(p0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, and our initial conditions, we want to run emcee. First, let's build the sampler object. We pass to it the number of walkers, the number of dimensions in our parameter space, the posterior function, and any arguments to the posterior function (i.e. our data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create sampler object\n",
    "sampler = emcee.EnsembleSampler(nwalkers=nwalkers, dim=2, lnpostfn=ln_posterior, args=(data,))\n",
    "\n",
    "# Burn-in\n",
    "pos,prob,state = sampler.run_mcmc(p0, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The output samples are stored in a variable associated with the sampler object called \"chain\"\n",
    "print(sampler.chain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the trace\n",
    "fig, ax = plt.subplots(2,1, figsize=(5,8))\n",
    "\n",
    "# Plot trace\n",
    "for i in range(2):\n",
    "    for j in range(nwalkers):\n",
    "        ax[i].plot(sampler.chain[j,:,i], alpha=0.1, color='k')\n",
    "\n",
    "    ax[i].axhline(truths[i], color='r')\n",
    "        \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset the sampler, restart the sampler at this current position, which we saved from before and called \"pos\"\n",
    "sampler.reset()\n",
    "pos,prob,state = sampler.run_mcmc(pos, N=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corner.corner(sampler.flatchain, truths=truths)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_x = np.linspace(1, 60, 10)\n",
    "\n",
    "# Plot data points\n",
    "plt.errorbar(data[:,0], data[:,1], yerr=data[:,2], label='Observations', fmt='o')\n",
    "\n",
    "# Plot samples\n",
    "samples = sampler.flatchain[np.random.randint(len(sampler.flatchain), size=30)]\n",
    "for sample in samples:\n",
    "    plt.plot(tmp_x, get_val(tmp_x, sample), color='k', alpha=0.15)\n",
    "\n",
    "# Plot Input values\n",
    "plt.plot(tmp_x, get_val(tmp_x, truths), color='r', label='Input Model', linewidth=2)\n",
    "\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's add some censored data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that your telescope is not sensitive enough to see anything with a magnitude below 35 or above 55. We will do this in a contrived way as an introduction to censored data. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The input values will be called \"truths\"\n",
    "m_truth = 0.5\n",
    "b_truth = 30.5\n",
    "truths = m_truth, b_truth\n",
    "\n",
    "# We will have a wavelength resolution of 1 - We will draw values as before\n",
    "data = np.zeros((100, 3))\n",
    "data[:,0] = np.random.uniform(1, 60, size=100)\n",
    "data[:,2] = np.random.uniform(5, 15, size=100)\n",
    "data[:,1] = get_val(data[:,0], truths) + np.random.normal(loc=0,scale=data[:,2],size=100)\n",
    "\n",
    "\n",
    "# Now, we will values in which the line would have given values below 35 and put in separate array\n",
    "u_limits = np.zeros((len(np.where(get_val(data[:,0], truths)<35)[0]), 2))\n",
    "u_limits[:,0] = data[get_val(data[:,0], truths)<35,0]\n",
    "data = data[get_val(data[:,0], truths)>=35,:]\n",
    "u_limits[:,1] = 35\n",
    "\n",
    "\n",
    "# Same for values in which the line would have given values above 55 and put in separate array\n",
    "l_limits = np.zeros((len(np.where(get_val(data[:,0], truths)>55)[0]), 2))\n",
    "l_limits[:,0] = data[get_val(data[:,0], truths)>55,0]\n",
    "data = data[get_val(data[:,0], truths)<=55,:]\n",
    "l_limits[:,1] = 55\n",
    "\n",
    "\n",
    "\n",
    "# Plot Input values\n",
    "tmp_x = np.linspace(1, 60, 10)\n",
    "plt.plot(tmp_x, get_val(tmp_x, truths), color='r', label='Input Model', linewidth=2)\n",
    "\n",
    "# Plot data points\n",
    "plt.errorbar(data[:,0], data[:,1], yerr=data[:,2], label='Observations', fmt='o')\n",
    "\n",
    "# Plot limits\n",
    "plt.errorbar(u_limits[:,0], u_limits[:,1], yerr=3, uplims=True, color='C0', fmt='o')\n",
    "plt.errorbar(l_limits[:,0], l_limits[:,1], yerr=3, lolims=True, color='C0', fmt='o')\n",
    "\n",
    "\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we need to adjust the likelihood and posterior functions to include lower and upper limits\n",
    "\n",
    "How do we do this? To first order, we will do something very simple: we will say that any model inconsistent with the upper and lower limits has a likelihood of 0 (a log likelihood of -infinity). Mathematically, we can separate our observations into three types: $x_{\\rm obs}$ (an observations with a data point), $x_{\\rm upper}$ (an upper limit), and $x_{\\rm low}$ (a lower limit):\n",
    "\n",
    "\\begin{aligned}\n",
    "P(D|M) &= \\\\\n",
    "&= P(\\{x_{\\rm obs}\\}, \\{ x_{\\rm upper} \\}, \\{ x_{\\rm lower} \\} | M) \\\\\n",
    "&= \\prod_i P(x_{\\rm obs,i} | M)\\ \\prod_i P(x_{\\rm upper,i} | M)\\ \\prod_i P(x_{\\rm lower,i} | M) \n",
    "\\end{aligned}\n",
    "\n",
    "Since we only care about the log of the likelihood:\n",
    "$$\n",
    "\\ln P(D|M) = \\sum_i \\ln P(x_{\\rm obs, i} | M)\\ + \\sum_i \\ln P(x_{\\rm upper, i} | M) + \\sum_i \\ln P(x_{\\rm lower,i} | M) \n",
    "$$\n",
    "\n",
    "From last week:\n",
    "$$\n",
    "\\ln P(x_{\\rm obs, i} | M) = \\frac{-1}{2} \\ln \\left(2 \\pi \\sigma_{\\rm obs,i}^2\\right) + -\\frac{(x_{\\rm obs,i} - x_{\\rm model,i})^2}{2 \\sigma_{\\rm obs,i}^2} \n",
    "$$\n",
    "\n",
    "Now, we add our upper and lower limits:\n",
    "\n",
    "$$\n",
    "\\ln P(x_{\\rm upper, i} | M) = \n",
    "\\begin{cases}\n",
    "0 & x_{\\rm upper, i} \\geq x_{\\rm model, i} \\\\\n",
    "-\\infty & x_{\\rm upper, i} < x_{\\rm model, i} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\ln P(x_{\\rm lower, i} | M) = \n",
    "\\begin{cases}\n",
    "0 & x_{\\rm lower, i} \\leq x_{\\rm model, i} \\\\\n",
    "-\\infty & x_{\\rm lower, i} > x_{\\rm model, i} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We combine these into a new likelihood function below. We take lower and upper limits as optional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ln_likelihood(p, data, l_limits=None, u_limits=None):\n",
    "        \n",
    "    x_vals = data[:,0]\n",
    "    y_vals = data[:,1]\n",
    "    y_errs = data[:,2]\n",
    "    \n",
    "    y_model = get_val(x_vals, p)\n",
    "    \n",
    "    ll = np.sum(-0.5*np.log(2.0*np.pi*y_errs**2)) + np.sum(-(y_model-y_vals)**2 / (2.0*y_errs**2))\n",
    "    \n",
    "    if l_limits is not None:\n",
    "        y_limits = get_val(l_limits[:,0], p)\n",
    "        if np.any(l_limits[:,1] > y_limits): return -np.inf\n",
    "\n",
    "    if u_limits is not None:\n",
    "        y_limits = get_val(u_limits[:,0], p)\n",
    "        if np.any(u_limits[:,1] < y_limits): return -np.inf\n",
    "    \n",
    "    return ll\n",
    "\n",
    "\n",
    "def ln_posterior(p, data, l_limits=None, u_limits=None):\n",
    "    \n",
    "    lp = ln_prior(p)\n",
    "    if np.isinf(lp): return -np.inf\n",
    "    \n",
    "    ll = ln_likelihood(p, data, l_limits, u_limits)\n",
    "    if np.isinf(ll): return -np.inf\n",
    "\n",
    "    return lp+ll\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's generate our initial walker positions and run our model\n",
    "\n",
    "A few notes. First, we need to generate the walkers in a valid region of parameter space. Second, we now have to pass l_limits and u_limits as arguments to the posterior function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwalkers = 32\n",
    "\n",
    "m_set = np.random.normal(loc=7.0, scale=1.0, size=32)\n",
    "b_set = np.random.normal(loc=-100.0, scale=1.0, size=32)\n",
    "\n",
    "p0 = np.array([m_set, b_set]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create sampler object\n",
    "sampler = emcee.EnsembleSampler(nwalkers=nwalkers, dim=2, lnpostfn=ln_posterior, args=(data,l_limits, u_limits))\n",
    "\n",
    "# Burn-in\n",
    "pos,prob,state = sampler.run_mcmc(p0, N=1000)\n",
    "\n",
    "# Actual run\n",
    "sampler.reset()\n",
    "pos,prob,state = sampler.run_mcmc(pos, N=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the trace, covariance in the posterior distribution, and posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize=(5,8))\n",
    "\n",
    "# Plot trace\n",
    "for i in range(2):\n",
    "    for j in range(nwalkers):\n",
    "        ax[i].plot(sampler.chain[j,:,i], alpha=0.1, color='k')\n",
    "\n",
    "\n",
    "    ax[i].axhline(truths[i], color='r')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corner.corner(sampler.flatchain, truths=truths)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot Input values\n",
    "tmp_x = np.linspace(1, 60, 10)\n",
    "\n",
    "# Plot data points\n",
    "plt.errorbar(data[:,0], data[:,1], yerr=data[:,2], label='Observations', fmt='o')\n",
    "\n",
    "# Plot limits\n",
    "plt.errorbar(u_limits[:,0], u_limits[:,1], yerr=3, uplims=True, color='C0', fmt='o')\n",
    "plt.errorbar(l_limits[:,0], l_limits[:,1], yerr=3, lolims=True, color='C0', fmt='o')\n",
    "\n",
    "# Plot samples\n",
    "samples = sampler.flatchain[np.random.randint(len(sampler.flatchain), size=30)]\n",
    "for sample in samples:\n",
    "    plt.plot(tmp_x, get_val(tmp_x, sample), color='k', alpha=0.15)\n",
    "\n",
    "\n",
    "plt.plot(tmp_x, get_val(tmp_x, truths), color='r', label='Input Model', linewidth=2)\n",
    "\n",
    "\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Notice that the posterior distribution is biased. With your partner, try to explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's create a model with outliers\n",
    "\n",
    "We start by generating a model in which 10% of data are outliers. For simplicity, we will start with only 10 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The input values will be called \"truths\"\n",
    "m_truth = 10.5\n",
    "b_truth = 30.5\n",
    "mu_b_truth = 350\n",
    "sigma_b_truth = 20\n",
    "truths = m_truth, b_truth, mu_b_truth, sigma_b_truth\n",
    "\n",
    "\n",
    "\n",
    "# We will have a wavelength resolution of 1 - Generate 90 values\n",
    "data = np.zeros((100, 3))\n",
    "data[0:90,0] = np.random.uniform(1, 60, size=90)\n",
    "data[0:90,2] = np.random.uniform(15, 25, size=90)\n",
    "data[0:90,1] = get_val(data[0:90,0], truths[0:2]) + np.random.normal(loc=0,scale=data[0:90,2],size=90)\n",
    "\n",
    "\n",
    "# Add 10 outliers from a Gaussian with an amplitude of 90+-2, with measurement uncertainties\n",
    "data[90:100,0] = np.random.uniform(1, 60, size=10)\n",
    "data[90:100,2] = np.random.uniform(15, 25, size=10)\n",
    "data[90:100,1] = np.random.normal(loc=mu_b_truth, scale=sigma_b_truth, size=10) \\\n",
    "                        + np.random.normal(loc=0,scale=data[9:10,2],size=10)\n",
    "\n",
    "\n",
    "# Plot Input values\n",
    "plt.plot(data[:,0], get_val(data[:,0], truths[0:2]), color='r', label='Input Model')\n",
    "\n",
    "# Plot data points\n",
    "plt.errorbar(data[0:90,0], data[0:90,1], yerr=data[0:90,2], label='Observations', fmt='o')\n",
    "plt.errorbar(data[90:100,0], data[90:100,1], yerr=data[90:100,2], label='Observations', fmt='o')\n",
    "\n",
    "\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with this is substantially trickier\n",
    "\n",
    "We want to come up with a model that can determine if any individual data point is an outlier. To approach this problem, we will go back to our initial model. Before, our model was comprised entirely of two parameters, a slope and an intercept: $x_{\\rm model,i}=f(m, b)$. Now we will do something much fancier. We will first model the background as a gaussian with a mean and variance $(\\mu_b, \\sigma_b)$. We will then add an additional model parameter for *every* data point, $C_{\\rm i}$. Our model now includes:\n",
    "\n",
    "$$\n",
    "M \\equiv \\left\\{m, b, \\mu_b, \\sigma_b, \\{ C_{\\rm i} \\} \\right\\},\n",
    "$$\n",
    "\n",
    "where $C$ represents a class index, either a zero (for an outlier) or a one (for a genuine data point). Rather than two parameters, our model now has $4+N$ parameters, where $N$ is the number of observations. This may seem complicated, once we work through it, it will become much clearer.\n",
    "\n",
    "First, if a data point has $C_{\\rm i}=1$, then the likelihood function is exactly as we have seen above:\n",
    "$$\n",
    "\\ln P(x_{\\rm obs, i} | M, C_{\\rm i}=1) = \\frac{-1}{2} \\ln \\left(2 \\pi \\sigma_{\\rm obs,i}^2\\right) -\\frac{(x_{\\rm obs,i} - x_{\\rm model,i})^2}{2 \\sigma_{\\rm obs,i}^2} \n",
    "$$\n",
    "\n",
    "If, instead, a data point has $C_{\\rm i}=0$, then the likelihood function should follow our model for the background. What does this model look like mathematically? Instead of having a line, we have a Gaussian that is horizontally flat (i.e., no dependence on $x$). So we have data drawn from a Gaussian (with mean $\\mu_b$ and variance $\\sigma_b^2$), with a Gaussian uncertainty (with mean zero and variance $\\sigma_{\\rm obs,i}$). This is equivalent to a third Gaussian with mean $\\mu_b$ and variance $(\\sigma_{\\rm obs,i}^2 + \\sigma_b^2)$. Our log likelihood function for outliers is very similar to the one above:\n",
    "$$\n",
    "\\ln P(x_{\\rm obs, i} | M, C_{\\rm i}=0) = \\frac{-1}{2} \\ln \\left[2 \\pi \\left(\\sigma_{\\rm obs,i}^2 + \\sigma_b^2 \\right)\\right] -\\frac{(x_{\\rm obs,i} - \\mu_b)^2}{2 \\left( \\sigma_{\\rm obs,i}^2 + \\sigma_b^2 \\right)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Code our new likelihood function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ln_prior(p):\n",
    "    \n",
    "    \n",
    "    m, b, mu_b, sigma_b = p[0:4]\n",
    "    C_set = p[4:]\n",
    "    \n",
    "    lp = 0.0\n",
    "    \n",
    "    # No priors are actually necessary here, but we can set something just to be rigorous\n",
    "    # Prior on m\n",
    "    if m<-1.0e99 or m>1.0e99: return -np.inf\n",
    "    \n",
    "    # Prior on b\n",
    "    if b<-1.0e99 or b>1.0e99: return -np.inf\n",
    "    \n",
    "    # Priors on the Gaussian background\n",
    "    if mu_b < 0.0: return -np.inf\n",
    "    if sigma_b < 0.0: return -np.inf\n",
    "    \n",
    "    # Prior on C_set\n",
    "    if np.any(C_set < 0.0) or np.any(C_set>2.0): return -np.inf\n",
    "    \n",
    "    return lp\n",
    "\n",
    "\n",
    "def ln_likelihood(p, data):\n",
    "    \n",
    "    \n",
    "    m, b, mu_b, sigma_b = p[0:4]\n",
    "    C_set = p[4:]\n",
    "        \n",
    "    x_vals = data[:,0]\n",
    "    y_vals = data[:,1]\n",
    "    y_errs = data[:,2]\n",
    "    \n",
    "    y_model = get_val(x_vals, (m,b))\n",
    "    \n",
    "    # Likelihood function below\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return ll\n",
    "\n",
    "\n",
    "def ln_posterior(p, data):\n",
    "    \n",
    "    lp = ln_prior(p)\n",
    "    if np.isinf(lp): return -np.inf\n",
    "    \n",
    "    ll = ln_likelihood(p, data)\n",
    "    \n",
    "    return lp+ll\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nwalkers = 300\n",
    "\n",
    "m_set = np.random.normal(loc=20.0, scale=1.0, size=nwalkers)\n",
    "b_set = np.random.normal(loc=10.0, scale=1.0, size=nwalkers)\n",
    "mu_b_set = np.random.normal(loc=300, scale=1.0, size=nwalkers)\n",
    "sigma_b_set = np.random.normal(loc=1.0, scale=0.1, size=nwalkers)\n",
    "#C_set = np.random.uniform(0.0, 2.0, size=(32, 10))\n",
    "C_set = np.random.normal(1.0, 0.01, size=(nwalkers, 100))\n",
    "\n",
    "p0 = np.array([m_set, b_set, mu_b_set, sigma_b_set])\n",
    "p0 = np.vstack([p0, C_set.T]).T\n",
    "\n",
    "print(p0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create sampler object\n",
    "sampler = emcee.EnsembleSampler(nwalkers=nwalkers, dim=4+len(data), lnpostfn=ln_posterior, args=(data,))\n",
    "\n",
    "# Burn-in\n",
    "pos,prob,state = sampler.run_mcmc(p0, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,1, figsize=(5,12))\n",
    "\n",
    "# Plot trace\n",
    "for i in range(4):\n",
    "    for j in range(nwalkers):\n",
    "        ax[i].plot(sampler.chain[j,:,i], alpha=0.01, color='k')\n",
    "\n",
    "    ax[i].axhline(truths[i], color='r')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler.reset()\n",
    "pos,prob,state = sampler.run_mcmc(pos, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,1, figsize=(5,12))\n",
    "\n",
    "# Plot trace\n",
    "for i in range(4):\n",
    "    for j in range(nwalkers):\n",
    "        ax[i].plot(sampler.chain[j,:,i], alpha=0.01, color='k')\n",
    "\n",
    "    ax[i].axhline(truths[i], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corner.corner(sampler.flatchain[:,0:4], truths=truths)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the distribution of error labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.zeros(len(data))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    \n",
    "    mean[i] = np.mean(sampler.chain[:,:,i+4])\n",
    "    \n",
    "plt.hist(mean)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the posterior samples to identify which points are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_1 = np.where(mean > 0.8)[0]\n",
    "\n",
    "idx_2 = np.where(mean < 0.8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot Input values\n",
    "plt.plot(data[:,0], get_val(data[:,0], truths[0:2]), color='r', label='Input Model')\n",
    "\n",
    "# Plot data points\n",
    "plt.errorbar(data[idx_1,0], data[idx_1,1], yerr=data[idx_1,2], label='Observations', fmt='o', color='C0')\n",
    "plt.errorbar(data[idx_2,0], data[idx_2,1], yerr=data[idx_2,2], label='Observations', fmt='o', color='C1')\n",
    "# plt.errorbar(data[0:90,0], data[0:90,1], yerr=data[0:90,2], label='Observations', fmt='o')\n",
    "# plt.errorbar(data[90:100,0], data[90:100,1], yerr=data[90:100,2], label='Observations', fmt='o')\n",
    "\n",
    "\n",
    "# Plot samples\n",
    "tmp_x = np.linspace(1,60,10)\n",
    "samples = sampler.flatchain[np.random.randint(len(sampler.flatchain), size=30)]\n",
    "for sample in samples:\n",
    "    plt.plot(tmp_x, get_val(tmp_x, sample[0:2]), color='k', alpha=0.15)\n",
    "\n",
    "\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# plt.ylim(0,120)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
